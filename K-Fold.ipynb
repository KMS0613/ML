{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26bcbf8d",
   "metadata": {},
   "source": [
    "#### sklearn.model_selection.KFold¶\n",
    "\n",
    "- class sklearn.model_selection.KFold(n_splits=5, *, shuffle=False, random_state=None)[source]\n",
    "\n",
    "-   Parameters:\n",
    "    n_splitsint, default=5\n",
    "    Number of folds. Must be at least 2.\n",
    "\n",
    "    Changed in version 0.22: n_splits default value changed from 3 to 5.\n",
    "\n",
    "    shufflebool, default=False\n",
    "    Whether to shuffle the data before splitting into batches. Note that the samples within each split will not be shuffled.\n",
    "\n",
    "    random_stateint, RandomState instance or None, default=None\n",
    "    When shuffle is True, random_state affects the ordering of the indices, which controls the randomness of each fold. Otherwise, this         parameter has no effect. Pass an int for reproducible output across multiple function calls. See Glossary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91a351ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=None, shuffle=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np \n",
    "\n",
    "iris = load_iris()\n",
    "features = iris.data \n",
    "label = iris.target\n",
    "dt_clf = DecisionTreeClassifier(random_state = 156)\n",
    "\n",
    "kfold = KFold(n_splits=5)\n",
    "cv_acuuracy=[]\n",
    "print(kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed6ccbca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
      "        43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "        56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,\n",
      "        69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,\n",
      "        82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,\n",
      "        95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,\n",
      "       108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
      "       121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133,\n",
      "       134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,\n",
      "       147, 148, 149]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]))\n",
      "(array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  60,  61,  62,  63,  64,  65,  66,  67,  68,\n",
      "        69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,\n",
      "        82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,\n",
      "        95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,\n",
      "       108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
      "       121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133,\n",
      "       134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,\n",
      "       147, 148, 149]), array([30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46,\n",
      "       47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]))\n",
      "(array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  90,  91,  92,  93,  94,\n",
      "        95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,\n",
      "       108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
      "       121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133,\n",
      "       134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,\n",
      "       147, 148, 149]), array([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76,\n",
      "       77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89]))\n",
      "(array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89, 120,\n",
      "       121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133,\n",
      "       134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,\n",
      "       147, 148, 149]), array([ 90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102,\n",
      "       103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115,\n",
      "       116, 117, 118, 119]))\n",
      "(array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "       117, 118, 119]), array([120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132,\n",
      "       133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145,\n",
      "       146, 147, 148, 149]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in kfold.split(features):\n",
    "    print(i)\n",
    "    \n",
    "# split할 경우 인덱스 번호를 반환. 이렇게 인덱스 번호를 주는 이유는 동일한 인덱스 번호를 가지는 데이터의 라벨 값을 뽑아내야 하기 때문.\n",
    "\n",
    "label[[\n",
    "    30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
    "        43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
    "        56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,\n",
    "        69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,\n",
    "        82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,\n",
    "        95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,\n",
    "       108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
    "       121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133,\n",
    "       134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,\n",
    "       147, 148, 149]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4103a653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1교차 검증 정확도: 1.0, 학습 데이터 크기: 120, 검증 데이터 크기[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "1검증 세트 인덱스[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "2교차 검증 정확도: 0.9667, 학습 데이터 크기: 120, 검증 데이터 크기[30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "2검증 세트 인덱스[30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "3교차 검증 정확도: 0.8667, 학습 데이터 크기: 120, 검증 데이터 크기[60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " 84 85 86 87 88 89]\n",
      "3검증 세트 인덱스[60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " 84 85 86 87 88 89]\n",
      "4교차 검증 정확도: 0.9333, 학습 데이터 크기: 120, 검증 데이터 크기[ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "4검증 세트 인덱스[ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "5교차 검증 정확도: 0.7333, 학습 데이터 크기: 120, 검증 데이터 크기[120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "5검증 세트 인덱스[120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "평균 검증 정확도: 0.9\n"
     ]
    }
   ],
   "source": [
    "n_iter = 0 # 반복횟수 세는 용 \n",
    "cv_acuuracy=[]\n",
    "\n",
    "for train_index, valid_index in kfold.split(features): #kfold.split으로 데이터 인덱스들 뽑아내기 가능. \n",
    "    X_train, X_valid = features[train_index], features[valid_index]\n",
    "    y_train, y_valid = label[train_index], label[valid_index] #해당인덱스의 라벨값들 \n",
    "    \n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred = dt_clf.predict(X_valid)\n",
    "    n_iter = n_iter+1\n",
    "    \n",
    "    accuracy= np.round(accuracy_score(y_valid, pred), 4)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_valid.shape[0]\n",
    "    print(f'{n_iter}교차 검증 정확도: { accuracy}, 학습 데이터 크기: {train_size}, 검증 데이터 크기{valid_index}')\n",
    "    \n",
    "    print(f'{n_iter}검증 세트 인덱스{valid_index}')\n",
    "    cv_acuuracy.append(accuracy)\n",
    "    \n",
    "print('평균 검증 정확도:', np.mean(cv_acuuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd8c6f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1교차 검증 정확도: 0.0, 학습 데이터 크기: 100, 검증 데이터 크기[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "\n",
      "1검증 세트 인덱스[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49]\n",
      "\n",
      "2교차 검증 정확도: 0.0, 학습 데이터 크기: 100, 검증 데이터 크기[50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73\n",
      " 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97\n",
      " 98 99]\n",
      "\n",
      "2검증 세트 인덱스[50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73\n",
      " 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97\n",
      " 98 99]\n",
      "\n",
      "3교차 검증 정확도: 0.0, 학습 데이터 크기: 100, 검증 데이터 크기[100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135\n",
      " 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      "3검증 세트 인덱스[100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135\n",
      " 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "평균 검증 정확도: 0.0\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=3)\n",
    "cv_acuuracy=[]\n",
    "n_iter = 0 \n",
    "\n",
    "for train_index, valid_index in kfold.split(features): #kfold.split으로 데이터 인덱스들 뽑아내기 가능. \n",
    "    X_train, X_valid = features[train_index], features[valid_index]\n",
    "    y_train, y_valid = label[train_index], label[valid_index] #해당인덱스의 라벨값들 \n",
    "    \n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred = dt_clf.predict(X_valid)\n",
    "    n_iter = n_iter+1\n",
    "    \n",
    "    accuracy= np.round(accuracy_score(y_valid, pred), 4)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_valid.shape[0]\n",
    "    print(f'\\n{n_iter}교차 검증 정확도: { accuracy}, 학습 데이터 크기: {train_size}, 검증 데이터 크기{valid_index}')\n",
    "    \n",
    "    print(f'\\n{n_iter}검증 세트 인덱스{valid_index}')\n",
    "    cv_acuuracy.append(accuracy)\n",
    "    \n",
    "print('평균 검증 정확도:', np.mean(cv_acuuracy))\n",
    "\n",
    "# 라벨이 50개씩이니까 0 은 0만, 1은 1만, 2는 2만 예측함. 즉, 검증이 전혀 안됨. 즉, KFold 사용시 순서대로 뽑기 때문에 \n",
    "# 데이터 불균형이 발생할 가능성이 높음. 따라서 stratified하게 섞을 것. (층화추출) 따로 패키지 있음. \n",
    "# 레이블 보고 균형있게 가져와야 함 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74768df5",
   "metadata": {},
   "source": [
    "#### sklearn.model_selection.StratifiedKFold\n",
    "- class sklearn.model_selection.StratifiedKFold(n_splits=5, *, shuffle=False, random_state=None\n",
    "\n",
    "    Parameters:\n",
    "    n_splitsint, default=5\n",
    "    Number of folds. Must be at least 2.\n",
    "\n",
    "    Changed in version 0.22: n_splits default value changed from 3 to 5.\n",
    "\n",
    "    shufflebool, default=False\n",
    "    Whether to shuffle each class’s samples before splitting into batches. Note that the samples within each split will not be shuffled.\n",
    "\n",
    "    random_stateint, RandomState instance or None, default=None\n",
    "    When shuffle is True, random_state affects the ordering of the indices, which controls the randomness of each fold for each class.         Otherwise, leave random_state as None. Pass an int for reproducible output across multiple function calls. See Glossary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f486e7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 교차검증 1 \n",
      "label\n",
      "2    34\n",
      "0    33\n",
      "1    33\n",
      "Name: count, dtype: int64\n",
      "## 교차 검증 : 1\n",
      "학습 레이블 데이터 분포:\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "검증 레이블 데이터 분포:\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "## 교차검증 2 \n",
      "label\n",
      "1    34\n",
      "0    33\n",
      "2    33\n",
      "Name: count, dtype: int64\n",
      "## 교차 검증 : 2\n",
      "학습 레이블 데이터 분포:\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "검증 레이블 데이터 분포:\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "## 교차검증 3 \n",
      "label\n",
      "0    34\n",
      "1    33\n",
      "2    33\n",
      "Name: count, dtype: int64\n",
      "## 교차 검증 : 3\n",
      "학습 레이블 데이터 분포:\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "검증 레이블 데이터 분포:\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pandas as pd\n",
    "\n",
    "iris_df = pd.DataFrame(features, columns=iris.feature_names)\n",
    "iris_df['label'] = iris.target\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 3)\n",
    "n_iter = 0\n",
    "\n",
    "for train_index, valid_index in skf.split(features, label):\n",
    "    n_iter = n_iter + 1\n",
    "    label_train = label[train_index] #train_index[label]은 오류남. \n",
    "    label_valid = label[valid_index]\n",
    "    \n",
    "    label_train2 = iris_df['label'].iloc[train_index]\n",
    "    label_test2 = iris_df['label'].iloc[valid_index]\n",
    "    print(f'## 교차검증 {n_iter} ')\n",
    "    print(label_train2.value_counts())\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(f'## 교차 검증 : {n_iter}')\n",
    "    print(f'학습 레이블 데이터 분포:\\n', label_train)\n",
    "    print(f'검증 레이블 데이터 분포:\\n', label_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b5024116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1교차 검증 정확도: 0.9667, 학습 데이터 크기: 120, 검증 데이터 크기[  0   1   2   3   4   5   6   7   8   9  50  51  52  53  54  55  56  57\n",
      "  58  59 100 101 102 103 104 105 106 107 108 109]\n",
      "\n",
      "1검증 세트 인덱스[  0   1   2   3   4   5   6   7   8   9  50  51  52  53  54  55  56  57\n",
      "  58  59 100 101 102 103 104 105 106 107 108 109]\n",
      "\n",
      "2교차 검증 정확도: 0.9667, 학습 데이터 크기: 120, 검증 데이터 크기[ 10  11  12  13  14  15  16  17  18  19  60  61  62  63  64  65  66  67\n",
      "  68  69 110 111 112 113 114 115 116 117 118 119]\n",
      "\n",
      "2검증 세트 인덱스[ 10  11  12  13  14  15  16  17  18  19  60  61  62  63  64  65  66  67\n",
      "  68  69 110 111 112 113 114 115 116 117 118 119]\n",
      "\n",
      "3교차 검증 정확도: 0.9, 학습 데이터 크기: 120, 검증 데이터 크기[ 20  21  22  23  24  25  26  27  28  29  70  71  72  73  74  75  76  77\n",
      "  78  79 120 121 122 123 124 125 126 127 128 129]\n",
      "\n",
      "3검증 세트 인덱스[ 20  21  22  23  24  25  26  27  28  29  70  71  72  73  74  75  76  77\n",
      "  78  79 120 121 122 123 124 125 126 127 128 129]\n",
      "\n",
      "4교차 검증 정확도: 0.9667, 학습 데이터 크기: 120, 검증 데이터 크기[ 30  31  32  33  34  35  36  37  38  39  80  81  82  83  84  85  86  87\n",
      "  88  89 130 131 132 133 134 135 136 137 138 139]\n",
      "\n",
      "4검증 세트 인덱스[ 30  31  32  33  34  35  36  37  38  39  80  81  82  83  84  85  86  87\n",
      "  88  89 130 131 132 133 134 135 136 137 138 139]\n",
      "\n",
      "5교차 검증 정확도: 1.0, 학습 데이터 크기: 120, 검증 데이터 크기[ 40  41  42  43  44  45  46  47  48  49  90  91  92  93  94  95  96  97\n",
      "  98  99 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      "5검증 세트 인덱스[ 40  41  42  43  44  45  46  47  48  49  90  91  92  93  94  95  96  97\n",
      "  98  99 140 141 142 143 144 145 146 147 148 149]\n",
      "평균 검증 정확도: 0.5500071428571429\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cv_accuracy=[]\n",
    "\n",
    "n_iter+=0\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pandas as pd\n",
    "\n",
    "iris_df = pd.DataFrame(features, columns=iris.feature_names)\n",
    "iris_df['label'] = iris.target\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "cv_accuracy = []\n",
    "\n",
    "n_iter = 0\n",
    "for train_index, valid_index in skf.split(features, label): #kfold.split으로 데이터 인덱스들 뽑아내기 가능. \n",
    "    X_train, X_valid = features[train_index], features[valid_index]\n",
    "    y_train, y_valid = label[train_index], label[valid_index] #해당인덱스의 라벨값들 \n",
    "    \n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred = dt_clf.predict(X_valid)\n",
    "    n_iter = n_iter+1\n",
    "    \n",
    "    accuracy= np.round(accuracy_score(y_valid, pred), 4)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_valid.shape[0]\n",
    "    print(f'\\n{n_iter}교차 검증 정확도: { accuracy}, 학습 데이터 크기: {train_size}, 검증 데이터 크기{valid_index}')\n",
    "    \n",
    "    print(f'\\n{n_iter}검증 세트 인덱스{valid_index}')\n",
    "    cv_acuuracy.append(accuracy)\n",
    "    \n",
    "print('평균 검증 정확도:', np.mean(cv_acuuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c23ba4",
   "metadata": {},
   "source": [
    "#### sklearn.model_selection.cross_val_score\n",
    "\n",
    "- sklearn.model_selection.cross_val_score(estimator, X, y=None, *, groups=None, scoring=None, cv=None, n_jobs=None, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', error_score=nan\n",
    "- estimator는 돌릴 모델 의미. y값이 안들어가면 층화추출이 안되는것. 라벨링 불균형 해소 위해 y값 필수 cv는 몇번 반복할건지 \n",
    "- scoring을 바꾸면 정확도 말고 다른거도 가능 \n",
    "\n",
    "\n",
    "- Parameters:\n",
    "    estimatorestimator object implementing ‘fit’\n",
    "    The object to use to fit the data.\n",
    "\n",
    "    Xarray-like of shape (n_samples, n_features)\n",
    "    The data to fit. Can be for example a list, or an array.\n",
    "\n",
    "    yarray-like of shape (n_samples,) or (n_samples, n_outputs), default=None\n",
    "    The target variable to try to predict in the case of supervised learning.\n",
    "\n",
    "    groupsarray-like of shape (n_samples,), default=None\n",
    "    Group labels for the samples used while splitting the dataset into train/test set. Only used in conjunction with a “Group” cv instance (e.g., GroupKFold).\n",
    "\n",
    "    scoringstr or callable, default=None\n",
    "    A str (see model evaluation documentation) or a scorer callable object / function with signature scorer(estimator, X, y) which should return only a single value.\n",
    "\n",
    "    Similar to cross_validate but only a single metric is permitted.\n",
    "\n",
    "    If None, the estimator’s default scorer (if available) is used.\n",
    "\n",
    "    cvint, cross-validation generator or an iterable, default=None\n",
    "    Determines the cross-validation splitting strategy. Possible inputs for cv are:\n",
    "\n",
    "    None, to use the default 5-fold cross validation,\n",
    "\n",
    "    int, to specify the number of folds in a (Stratified)KFold,\n",
    "\n",
    "    CV splitter,\n",
    "\n",
    "    An iterable that generates (train, test) splits as arrays of indices.\n",
    "\n",
    "    For int/None inputs, if the estimator is a classifier and y is either binary or multiclass, StratifiedKFold is used. In all other cases, KFold is used. These splitters are instantiated with shuffle=False so the splits will be the same across calls.\n",
    "\n",
    "    Refer User Guide for the various cross-validation strategies that can be used here.\n",
    "\n",
    "    Changed in version 0.22: cv default value if None changed from 3-fold to 5-fold.\n",
    "\n",
    "    n_jobsint, default=None\n",
    "    Number of jobs to run in parallel. Training the estimator and computing the score are parallelized over the cross-validation splits. None means 1 unless in a joblib.parallel_backend context. -1 means using all processors. See Glossary for more details.\n",
    "\n",
    "    verboseint, default=0\n",
    "    The verbosity level.\n",
    "\n",
    "    fit_paramsdict, default=None\n",
    "    Parameters to pass to the fit method of the estimator.\n",
    "\n",
    "    pre_dispatchint or str, default=’2*n_jobs’\n",
    "    Controls the number of jobs that get dispatched during parallel execution. Reducing this number can be useful to avoid an explosion of memory consumption when more jobs get dispatched than CPUs can process. This parameter can be:\n",
    "\n",
    "    None, in which case all the jobs are immediately created and spawned. Use this for lightweight and fast-running jobs, to avoid delays due to on-demand spawning of the jobs\n",
    "\n",
    "    An int, giving the exact number of total jobs that are spawned\n",
    "\n",
    "    A str, giving an expression as a function of n_jobs, as in ‘2*n_jobs’\n",
    "\n",
    "    error_score‘raise’ or numeric, default=np.nan\n",
    "    Value to assign to the score if an error occurs in estimator fitting. If set to ‘raise’, the error is raised. If a numeric value is given, FitFailedWarning is raised.\n",
    "\n",
    "    New in version 0.20.\n",
    "\n",
    "    Returns:\n",
    "    scoresndarray of float of shape=(len(list(cv)),)\n",
    "    Array of scores of the estimator for each run of the cross validation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
